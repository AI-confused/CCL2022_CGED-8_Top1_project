data_dir: $CCL2022_CGED-8_Top1_project/dataset/
exp_dir: $CCL2022_CGED-8_Top1_project/Grammar_Error_Detect/Bert+CRF/output/
model_name: $chinese_macbert_large的地址
task_name: 'Grammar_detect_task_macbert-large_5e-6_linian-finetune_drop0.3_cosine'
skip_train: 0
scheduler: cosine
warmup_portion: 0.0
eval_portion: 0.5
train_file_name: jianti_14-18_train+test_charlevel/detect_all_data.jsonl
dev_file_name: jianti_14-18_train+test_charlevel/detect_dev.jsonl
load_test: 0
dropout: 0.3
max_seq_len: 256
train_batch_size: 256
eval_batch_size: 256
learning_rate: 5e-6
num_train_epochs: 10
no_cuda: False
# specify the GPU number
cuda_device: '0,1,2,3,4,5,6,7'
seed: 99
gradient_accumulation_steps: 1
over_write_cache: 1
resume_latest_cpt: 0
bad_case: 1
# save_cpt_flag value: {0: only save best model; 1: save best model & last epoch model; 2: save best model & each epoch model}
save_cpt_flag: 2
percent: 1.0